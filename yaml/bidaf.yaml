description: >
  BiDAF reader implementation as described in https://arxiv.org/abs/1611.01603. This is a slightly adapted version.

parent_config: './conf/qa/modular_qa.yaml'

# Reader model to use, see jack/readers/implementations.py for options
name: 'bidaf_reader'

# fixed experiment seed
seed: 1337

# where to store the reader
save_dir: './bidaf_reader'

with_char_embeddings: True

repr_dim: &dim 100
dropout: &dropout 0.2
max_span_size: 16

model:
  encoder_layer:
  # Embedding computation
  # Support
  - input: ['support', 'char_support']
    output: 'support'
    module: 'concat'
  - input: 'support'
    name: 'embedding_highway'
    module: 'highway'
    num_layers: 2

  # Question
  - input: ['question', 'char_question']
    output: 'question'
    module: 'concat'
  - input: 'question'
    name: 'embedding_highway'  # use same network as support
    module: 'highway'
    num_layers: 2

  # Contextual Encoding
  - input: 'question'
    module: 'lstm'
    name: 'contextual_encoding'
    with_projection: True # not in the original bidaf implementation, but help
    dropout: *dropout
  - input: 'support'
    module: 'lstm'
    with_projection: True # not in the original bidaf implementation, but helps
    name: 'contextual_encoding' # shared encoding at this point helps
    dropout: *dropout

  # Attention Encoding
  - input: 'support'
    dependent: 'question'
    module: 'bidaf'

  - input: 'support'
    module: 'lstm'
    with_projection: True # not in the original bidaf implementation, but helps
    num_layers: 2
    dropout: *dropout

  answer_layer:
    module: 'bidaf'
    repr_dim: *dim
    encoder:  # only needed for bidaf answer layer
      repr_dim: *dim
      module: 'lstm'
      dropout: *dropout
